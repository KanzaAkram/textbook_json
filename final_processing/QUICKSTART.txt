"""
QUICK START GUIDE - Final Processing Pipeline
"""

# ============================================================================
# FINAL PROCESSING PIPELINE - QUICK START
# ============================================================================

# What this does:
# 1. Matches subtopics across textbook, syllabus, and Save My Exam by subtopic number
# 2. Organizes matched files in staging directory
# 3. Sends to AI Studio with correct content hierarchy:
#    - TEXTBOOK (Primary) - main content source
#    - SYLLABUS (Fencing) - learning objectives define boundaries
#    - SAVE MY EXAM (Secondary) - supplementary content
# 4. Generates comprehensive JSON notes

# ============================================================================
# QUICK START
# ============================================================================

# Navigate to directory
cd final_processing

# Option 1: COMPLETE PIPELINE (with test limit)
python run_pipeline.py --limit 1    # Test with 1 subtopic per subject first

# Option 2: STEP BY STEP
python validate_setup.py            # 1. Validate setup
python matcher.py                   # 2. Match subtopics (creates staging/)
python processor.py --limit 2       # 3. Process 2 subtopics per subject (test)

# After testing is successful:
python run_pipeline.py              # Run full pipeline

# ============================================================================
# FILES CREATED
# ============================================================================

# Core Components:
# - config.py          : Configuration and AI prompt template
# - utils.py           : Utility functions (file I/O, PDF extraction, etc.)
# - matcher.py         : Matches subtopics across sources
# - processor.py       : Processes through AI Studio
# - run_pipeline.py    : Master pipeline runner
# - validate_setup.py  : Setup validator

# Documentation:
# - README_NEW.md      : Complete documentation
# - SUMMARY.md         : This summary
# - QUICKSTART.txt     : This file
# - requirements.txt   : Dependencies

# Generated Directories:
# - staging/           : Organized matched files with metadata
# - comprehensive_notes/ : AI-generated comprehensive notes (after processing)

# ============================================================================
# MATCHING RESULTS (Already Completed!)
# ============================================================================

# Alevel/9701:  39 subtopics (35 with all 3 sources, 4 with 2 sources)
# AS'Level/9701: 51 subtopics (ALL with all 3 sources!)

# Check results:
# - staging/Alevel/9701/_manifest.json
# - staging/AS'Level/9701/_manifest.json

# ============================================================================
# COMMAND OPTIONS
# ============================================================================

# run_pipeline.py:
#   --limit N          Process only first N subtopics per subject
#   --skip-matching    Skip matching, use existing staging

# processor.py:
#   --limit N          Process only first N subtopics per subject

# Examples:
python run_pipeline.py --limit 2              # Test with 2 per subject
python run_pipeline.py --skip-matching        # Use existing staging
python processor.py --limit 5                 # Process 5 per subject

# ============================================================================
# VALIDATION
# ============================================================================

# Check setup:
python validate_setup.py

# Expected output:
# âœ… All checks passed! Ready to run pipeline.

# Check matching results:
python -c "from pathlib import Path; print(f'Total matches: {sum(1 for p in Path(\"staging\").rglob(\"_metadata.json\"))}')"

# Check processing results:
python -c "from pathlib import Path; print(f'Total outputs: {len(list(Path(\"comprehensive_notes\").rglob(\"*.json\")))}')"

# ============================================================================
# LOGS AND DEBUGGING
# ============================================================================

# All operations logged to:
# - final_processing.log    : Detailed log file
# - Console                 : Real-time progress

# Check log:
# tail -f final_processing.log    # Linux/Mac
Get-Content final_processing.log -Wait    # Windows PowerShell

# ============================================================================
# TROUBLESHOOTING
# ============================================================================

# If AI Studio fails:
# 1. Check internet connection
# 2. Verify AI Studio login (may need manual login first)
# 3. Check textbook/config.py for correct AI Studio URL
# 4. Review final_processing.log for errors

# If no matches found:
# 1. Check source directories exist
# 2. Verify file naming: X.X_Name.ext (e.g., 1.1_Topic.json)
# 3. Review matcher.py logs

# If JSON parsing fails:
# 1. Check AI response in log
# 2. Try reducing content size in config.py
# 3. Test with --limit 1 for debugging

# ============================================================================
# PERFORMANCE
# ============================================================================

# Matching: ~1-5 seconds per subject
# AI Processing: ~60-120 seconds per subtopic
# Full pipeline: Several hours depending on number of subtopics

# Tips:
# - Always test with --limit first
# - Run matching once, then process in batches
# - Monitor AI Studio rate limits
# - Check logs for bottlenecks

# ============================================================================
# EXPECTED OUTPUT FORMAT
# ============================================================================

# comprehensive_notes/Alevel/9701/23.1_Lattice_energy_and_Born_Haber_cycles.json
{
  "subtopic_number": "23.1",
  "subtopic_name": "Lattice energy and Born-Haber cycles",
  "level": "Alevel",
  "subject_code": "9701",
  "comprehensive_notes": {
    "introduction": "...",
    "key_concepts": [...],
    "detailed_content": {...},
    "important_definitions": [...],
    "formulas_and_equations": [...],
    "summary": "...",
    "exam_tips": [...],
    "common_mistakes": [...]
  },
  "learning_objectives_coverage": {...},
  "metadata": {
    "generated_at": "2025-12-20T...",
    "sources_used": {
      "textbook": true,
      "syllabus": true,
      "save_my_exam_count": 1
    }
  }
}

# ============================================================================
# RECOMMENDED WORKFLOW
# ============================================================================

# Day 1: Setup and Testing
python validate_setup.py                    # Validate setup
python run_pipeline.py --limit 1            # Test with 1 subtopic per subject
# Review output in comprehensive_notes/
# Check final_processing.log for any issues

# Day 2: Small Batch
python run_pipeline.py --skip-matching --limit 5    # Process 5 per subject
# Review results, check quality

# Day 3+: Full Production
python run_pipeline.py --skip-matching      # Process all remaining
# Monitor progress via logs
# Check outputs periodically

# ============================================================================
# SUPPORT
# ============================================================================

# Documentation:
# - README_NEW.md : Complete documentation
# - SUMMARY.md    : Overview and results
# - This file     : Quick reference

# Logs:
# - final_processing.log : Detailed execution log

# For issues:
# 1. Check log file first
# 2. Review README_NEW.md troubleshooting section
# 3. Verify source file formats and AI Studio config

# ============================================================================
